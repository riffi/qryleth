# Взаимодействие LLM-агента с редактором

## Обзор

Документ описывает, как языковая модель взаимодействует с Qryleth и какие правила необходимо соблюдать.

---

## Принцип работы

Основная коммуникация с LLM построена на сервисе `LangChainChatService` (`src/shared/lib/langchain/chatService.ts`).

- При монтировании `ChatInterface` вызывается `langChainChatService.initialize()`, который читает активное подключение из `openAISettings` и создает модель `ChatOpenAI`.
- Инструменты сцены автоматически регистрируются через `registerSceneTools()`. Они описаны в `src/shared/lib/langchain/tools` и доступны агенту при генерации ответа.
- Сам чат выполняется методом `langChainChatService.chat(messages)`, внутри которого используется `createToolCallingAgent` из LangChain. Агент может вызывать зарегистрированные инструменты.
- Для обратной совместимости сохранена функция `fetchWithTools` из `openAIAPI.ts`; она применяется в debug‑панели и позволяет напрямую отправлять запрос к API без LangChain.
- Результат работы LangChain содержит сообщение ассистента и, при необходимости, сведения о выполненных инструментах. UI обновляет состояние сцены через публичные actions zustand‑стора.
- Агент не изменяет DOM напрямую и не обращается к внутреннему состоянию компонентов.

### Настройка подключений

Подключения к LLM описываются структурой `OpenAISettingsConnection` и хранятся в Dexie базе (`SceneLibraryDB`). Пользователь управляет списком подключений через модальное окно `OpenAISettingsModal`.

- Поддерживаются провайдеры `openrouter`, `openai` и `compatible`.
- Для каждого подключения сохраняются URL сервиса, название модели и API‑ключ.
- При выборе активного подключения `langChainChatService` переинициализируется с новыми параметрами.

Подробнее см. [Настройка подключений](provider-connections.md).

---

## Контракт


Структуры данных для общения с моделью определены в `openAIAPI.ts`:

- `ChatMessage` – роль, текст и время сообщения
- `Tool` – описание инструмента, который может быть вызван моделью
- `ToolCall` – фактический вызов с именем функции и аргументами
- `ChatResponse` – ответ модели, содержащий текст и список `ToolCall`

На данный момент поддерживается инструмент `add_new_object` с параметрами, описанными в `AVAILABLE_TOOLS`.

**Правила:**
- Модель обязана передавать аргументы в формате JSON, соответствующем схемам параметров инструментов. Неверный формат считается ошибкой
- Все манипуляции со сценой должны выполняться через публичные функции стора или пропсы компонентов (например, `onObjectAdded`)

---

##  Пример последовательности

1. Пользователь отправляет запрос в чат
2. `ChatInterface` передаёт полный список сообщений в `langChainChatService.chat()`
3. LangChain агент анализирует историю, при необходимости вызывает инструменты и возвращает текстовый ответ
4. Если был выполнен инструмент `add_new_object`, сервис вызывает callback `onObjectAdded`, и UI отображает дополнительное системное сообщение

---

##  Соответствие архитектуре


Такой подход гарантирует, что агенты работают предсказуемо и не нарушают архитектурные границы приложения.

## Связанные файлы

- `src/shared/lib/openAIAPI.ts` - API integration
- `features/ai-assistant/hooks/useAICommands.ts` - Command mapping
- [Design Principles](../../architecture/design-principles.md) - Architecture guidelines
